The term Human-Computer Interaction (HCI) refers to the study of interaction between humans and computers. The scientific field of HCI has seen considerable advancements in the last 30 years, especially since the publication of Card, Moran and Newell’s Psychology of Human Computer Interaction in 1983. Most of the research efforts in HCI attempt to make use of human skills and abilities that are naturally developed by leading a life in this physical world. One can classify different paradigms of interaction that take place between humans and computers:

\subsection{Command lines}

Initial interfaces were command-line interfaces where a user sits in front of a terminal screen, and enters a line specific command to perform specific tasks and wait for a reply. Only a part of the terminal screen real estate was used. Some of the concepts that were introduced were the concept of infinite loop (prompt), the immediate execution of commands (enter), a syntax allowing obligatory or optional parameters, the maintenance of a history of commands and the introduction of keyboard short-cuts. They were further improved with the introduction of textual interfaces that made use of the entire terminal screen.

\subsection{WIMP (Windows, icons, menus and pointers)}

The WIMP paradigm relies on Windows, Icons, Menus and Pointers to interact with the user.  

\begin{itemize}
\item A \textbf{window} runs a self-contained program, isolated from other programs that (if in a multi-programmed operating system) run at the same time in other windows.
\item An \textbf{icon} acts as a shortcut to an action the computer performs (e.g., execute a program or task).
\item A \textbf{menu} is a text or icon-based selection system that selects and executes programs or tasks.
\item The \textbf{pointer} is an on-screen symbol that represents movement of a physical device that the user controls to select icons, data elements, etc.
\end{itemize}

Post-WIMP comprises work on user interfaces, mostly graphical user interfaces, which attempt to go beyond this paradigm.

The reason WIMP interfaces have become so prevalent is that they are very \textbf{good at abstracting work-spaces}, documents and their actions. Their analogous paradigm to documents as paper sheets or folders makes WIMP interfaces easy to introduce to other users. 

However, WIMP interfaces are \textbf{not optimal for working with complex tasks} such as showing 3D models (computer-aided design), working on large amounts of data simultaneously (interactive games) or simply portraying an interaction for which there is no defined standard widget. WIMPs are usually \textbf{pixel-hungry}, so given limited screen real estate they can distract attention from the task at hand.  

\subsection{Direct manipulation interface}

It was introduced in the context of the creation of office applications and the desktop metaphor. It involves continuous representation of objects providing actions that are \textbf{rapid, reversible, incremental and with feedback}. These actions should correspond to \textbf{manipulation of physical objects}. Example: resizing a graphical shape by dragging its corners or edges with a mouse or doing a drag-n-drop to delete a file.

Benefits: can make it easier for a user to learn and use an interface, having rapid, incremental feedback allows a user to make fewer errors and complete tasks in less time.

\subsection{Form filling}

It is preferred for bureaucratic and routine tasks. Introduces the notion of obligatory, optional or conditional fields, the notion of unfolding menus, the guide of the user during the process and the use of short-cuts. It allows the automatic verification of inputs. Example: online reservation of a flight. 

\subsection{Experiment with the four previous paradigms}

The experiment that can be found \url{http://cs211labs.epfl.ch} does a simulation of the purchase of five tickets in each of the four previous interaction modes. The conclusion is that the best paradigm depends on the task, the user and the details of the design. 

Depending of the degree of use of the tool we can have:

\begin{itemize}
\item Beginner: retains aspects of task of the real world without computer.
\item Intermediate: advanced features that translate the task from the real world to the computer.
\item Expert: aspects of computer program that don't have to do with the task itself.
\end{itemize}

Example: if we take OpenOffice Word, 

\begin{itemize}
\item Beginner: to write an essay one needs an index, an introduction and a body.
\item Intermediate: to structure the body of the essay one needs to separate the text in paragraphs with convenient parameters.
\item Expert: knows where one has to find the different options or how we call specific actions.
\end{itemize}

\subsection{Virtual reality}

Computer interactive simulation using sound and visual effects corresponding to real, imaginary or semi-imaginary environments.

Examples: Minecraft (characters represented by avatars although the world is not real), eye surgery learning.

\subsubsection{Immersive simulation}

An interactive computer simulation is \textbf{immersive} if the user receives similar stimulus (sight, smell, touch or sound) to the ones he would receive in the environment that is being simulated. 

Examples: a cave automatic virtual environment (CAVE) is an immersive virtual reality environment where video projectors are directed to between three and six of the walls of a room-sized cube. CAVE is typically a video theatre situated within a larger room. The user wears 3D glasses inside the CAVE to see 3D graphics generated by it. People using the CAVE can see objects apparently floating in the air, and can walk around them, getting a proper view of what they would look like in reality. A CAVE user's movements are tracked by the sensors typically attached to the 3D glasses and the video continually adjusts to retain the viewers perspective.

\subsubsection{Influence on the users}

A question remains to be answered. Do these virtual reality experiences really influence the users as the real world does?. Several experiments have been conducted in this sense, measuring physiological and cognitive responses. For instance, virtual  reality  users  hearts  have  pumped intensely  while  crossing  a  virtual pit (walking through a piece of wood surrounded by virtual cliffs). 

\subsubsection{Haptic devices}

Different \textbf{haptic} (related to the touch sense) \textbf{devices} has been implemented. They give the sensation of touch by applying forces (force feedback) or vibrations to the movements of users. This needs the presence of sensors for measuring the forces applied by the user. The user can then feel the specific resistance, elasticity or rugosity of the surface.

Applications:  surgery simulations, bass shakers vibrations in cinemas. 

A particularly interesting application is a \textbf{data glove or wired glove}. It is an input device for human-computer interaction worn like a glove. Various sensor technologies are used to capture physical data such as bending of fingers. Often a motion tracker, such as a magnetic tracking device or inertial tracking device, is attached to capture the global position/rotation data of the glove. 

These movements are then interpreted by the software that accompanies the glove, so any one movement can mean any number of things. Gestures can then be categorized into useful information, such as to recognize sign language or other symbolic functions.

Expensive high-end wired gloves can also provide haptic feedback, which is a simulation of the sense of touch. This allows a wired glove to also be used as an output device. Wired gloves are often used in virtual reality environments and to mimic human hand movement by robots.


\subsection{Augmented reality}

Augmented reality (AR) , is a live direct or indirect view of a physical, real-world environment whose elements are augmented by computer-generated sensory input such as sound, video, graphics or GPS data. Augmentation techniques are typically performed in \textbf{real-time}, that is, there are time limits that must be met. To this real setting one normally adds supplemental information like scores over a live video feed of a sporting event.

There are several hardware instruments that can be used to this goal. Using transparencies such as glasses or projections. We can even have interactive surfaces where we should ask ourselves whether is better to project from the upside or from the downside. A special characteristic of this surfaces is whether they are \textbf{multi-touch} or not. Multi-touch means that we can recognize the presence of more than one or more than two points of contact with the surface.

\subsection{Difference between virtual reality and augmented reality}

Virtual reality offers a digital recreation of a real life setting, while augmented reality delivers virtual elements as an overlay to the real world. 

Augmented reality is a type of virtual reality technology that blends what the user sees in their real surroundings with digital content generated by computer software. The additional software-generated images with the virtual scene typically enhance how the real surroundings look in some way. 

\subsection{Tangible interaction}

Tangible Interaction has come to be the 'umbrella term' used to describe a set of related research and design approaches which have emerged in several disciplines. It covers user interfaces and interaction approaches that emphasize:

\begin{itemize}
\item tangibility and materiality of the interface which is then connected with sensors with the computer. This sensors can be in the form of cameras, touch-tables or RFID.
\item the objects employed are specific to the task at hand which can be the visit to a museum to learn about an specific topic or directed to children to learn programming. It is very usual that this physical environments are thought to be multi-user to enhance teamwork. 
\end{itemize}

\subsection{Voice command devices}

These are interfaces that allow the user to \textbf{communicate using its voice} with the computer. A popular system for this is Siri. However, there is still a lot to do in human voice recognition to generalize these tools.  The level of precision depends on factors like the size of the vocabulary of the user, the environmental noise, the time that a particular user has been using it since Siri claims that it can learn with time or certain others semantic problems. There are also certain challenges in its usability.

\subsection{Gesture control}

This interface is based in the \textbf{recognition of human gestures}. In EPFL, reseracher Fr\'ed\'eric Kaplan has developed such a system to simulate tennis games. Microsoft Kinect is also an example. It enables users to control and interact with their console/computer without the need for a game controller, through a natural user interface using gestures and spoken commands.

\subsection{Brain–computer interface}

These interfaces allow the \textbf{communication of the user's brain activity to the computer}. In EPFL, researchers have obtained results controlling a wheel-chair. The thoughts of the user activate specific brain patterns that are recorded by electroencephalography (EEG) using a helmet with electrodes. These patterns are then interpreted by a computer that transmits a command to the chair. Interestingly, it takes some time to the user of these systems to adapt their thoughts to the machines they use. It is a process of mutual apprenticeship between human and machine.

\subsection{Bionic interfaces}

Bionics is the application of biological methods and systems found in nature to the study and design of engineering systems and modern technology. Therefore a bionic interface is an interface that profits of this knowledge to communicate the user and the computer.

An interesting experiment was carried out in EPFL by the team of Silvestro M\'icera to make a bionic hand with which patients could adjust their force to take objects and identify their shape and texture. The prosthesis contained some sensors capable of reacting to the tension of artificial tendons at translating them into electric impulses. This electric signals could then be transmitted to the actual external nerves of the patient arm.

\subsection{Wearables interfaces}

Wearable technology or wearables are electronic devices with microcontrollers that can be worn on the body as implants or accessories. The designs often incorporate practical functions and features.

This can be used for instance for \textbf{sousveillance}, which is the recording of an activity by a participant in it by means of wearing certain objects. It has also been used in the fashion industry. CuteCircuit was the first fashion company offering smart textile-based garments that create an emotional experience for their wearers using smart textiles and micro electronics.

\subsection{Interaction ambient}

The notion of ambient devices revolves around core concept of \textbf{immediate access to information}. The original developers of the idea (HYATT, ROSE, 2002) state that in the majority of cases an ambient device is designed to provide support to people in carrying out their everyday activities in an easy and natural way. An average person living in a modern society is being overloaded with abundance of information on a daily basis. Through the introduction of ambient devices into their day-to-day routine an individual gains an opportunity to decrease the amount of effort to process incoming data, thus rendering self more informed and productive (ROSE, 2002).

The key issue lies within \textbf{taking Internet-based content} (e.g. traffic congestion, weather condition, stock market quotes) \textbf{and mapping it into a single, usually one-dimensional spectrum} (e.g. angle, colour). According to one of the concept originators David L. Rose this way the data is represented to an end user seamlessly, and its procurement requires an insignificant amount of cognitive load.

One of the examples of the ambient device technology is Ambient Orb, introduced by Ambient Devices in 2002 (KIRSNER, 2002). The device itself was a glowing sphere which was continuously displaying data through perpetual changes in colour. Ambient Orb was customizable in terms of content and its subsequent visual representation. For instance, when the device was set to monitor a particular stock market index (e.g. NASDAQ), the Orb glowed green/red to represent the upward/downward movement of the stock prices; alternatively, it turned amber when the index is unchanged. Nabeel Hyatt stated that the device was marketed as an interior design item with additional functionality.

\subsection{Final thoughts}

Often, interfaces are said to be intuitive. However, we all have to learn how things work. The fact that we think that an interface is intuitive is more related with the fact hat \textbf{we forget that we have learnt it}. To properly asses the quality of a good interface one has to measure:

\begin{itemize}
\item the learning curve
\item the time needed to complete tasks
\item the number of errors
\item the user satisfaction
\end{itemize}

\subsection{Exercises}

\begin{exercise}
Suppose a website for reserving plane tickets. Classify the following knowledges into the different categories:
\end{exercise}
\begin{itemize}
\item If a user waits very long before confirming his choice the session is stopped and he has to restart all the process. (related to the computer translation)
\item A user has to enter the departure and arrival airports that are in the scope of the company's flights. (related to the computer translation)
\item Each airport of the world has a code name in three letters. For instance, GVA for Geneva. (related to the task)
\item In Swiss.com if the user wants to reserve a ticket in business class, he has to click on "more options" in the first dialogue window. (related to syntax)
\item I can order the possible flights in terms of the number of layovers or the price. (related to the computer translation)
\end{itemize}

\begin{exercise}
A software program for 3D rendering offers multiple functionalities to architects. What interaction paradigm is the most appropiate for the listed tasks. (It is possible to have several).
\end{exercise}
\begin{itemize}
\item Position a numeric image of the furniture and the equipment in the interior of the future kitchen. (direct manipulation)
\item position a numeric image of the future house on a real image of the ground to understand ints integration in the landscape. (augmented reality)
\item Make the the listing of the required windows for each room of the house. (form filling)
\item Propose to the clients an immersive visit in their future house. (virtual reality)
\end{itemize}

